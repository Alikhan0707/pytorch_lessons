{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facca70a",
   "metadata": {},
   "source": [
    "1. Вам нужно будет загрузить и оформить датасет котиков, собак https://www.kaggle.com/andrewmvd/dog-and-cat-detection\n",
    "2. *Нужно будет произвести аугментацию данных\n",
    "\n",
    "3. Затем обучить нейронную сеть на получившемся датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "12a3b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /private/var/folders/yv/c8pj7ptn37x0f2cy3vcj2gyh0000gn/T/pip-req-build-wjrh6bhz\n",
      "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /private/var/folders/yv/c8pj7ptn37x0f2cy3vcj2gyh0000gn/T/pip-req-build-wjrh6bhz\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from pycocotools==2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cython>=0.27.3 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from pycocotools==2.0) (0.29.22)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from pycocotools==2.0) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2020.12.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (7.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp38-cp38-macosx_10_9_x86_64.whl size=89067 sha256=8fb66766de00e25897aa4596741c4942c264ece7465dae0ad74055e339b304d2\n",
      "  Stored in directory: /private/var/folders/yv/c8pj7ptn37x0f2cy3vcj2gyh0000gn/T/pip-ephem-wheel-cache-jmqw3zfm/wheels/56/da/49/cb71a7c450b59588934077f431100c05fbde50646ee84a8d40\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "05d1f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'vision' already exists and is not an empty directory.\n",
      "error: pathspec 'v0.3.0' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": [
    "# Download TorchVision repo to use some files from\n",
    "# references/detection\n",
    "!git clone https://github.com/pytorch/vision.git\n",
    "!git checkout v0.3.0\n",
    "\n",
    "!cp ./vision/references/detection/utils.py ./\n",
    "!cp ./vision/references/detection/transforms.py ./\n",
    "!cp ./vision/references/detection/coco_eval.py ./\n",
    "!cp ./vision/references/detection/engine.py ./\n",
    "!cp ./vision/references/detection/coco_utils.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9f54eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from seaborn import color_palette\n",
    "\n",
    "from pathlib import Path\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024db37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/Users/macbook/Downloads/archive-2/images'\n",
    "annotations_path = '/Users/macbook/Downloads/archive-2/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "636d4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(files_path):\n",
    "    \n",
    "    annotations_list = []\n",
    "    \n",
    "    for path in files_path:\n",
    "        \n",
    "        annotation_dict = {}\n",
    "        \n",
    "        root = ElementTree.parse(path).getroot()\n",
    "        \n",
    "        annotation_dict['filename'] = Path(images_path + '/' + root.find('./filename').text)\n",
    "        \n",
    "        annotation_dict['width'] = int(root.find('./size/width').text)\n",
    "        annotation_dict['height'] = int(root.find('./size/height').text)\n",
    "        \n",
    "        annotation_dict['class'] = root.find('./object/name').text\n",
    "        \n",
    "        annotation_dict['xmin'] = int(root.find('./object/bndbox/xmin').text)\n",
    "        annotation_dict['ymin'] = int(root.find('./object/bndbox/ymin').text)\n",
    "        annotation_dict['xmax'] = int(root.find('./object/bndbox/xmax').text)\n",
    "        annotation_dict['ymax'] = int(root.find('./object/bndbox/ymax').text)\n",
    "        \n",
    "        annotations_list.append(annotation_dict)\n",
    "    \n",
    "    dataframe = pd.DataFrame(annotations_list)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df09a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_xml(list(Path(annotations_path).glob('*.xml')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "60cc2938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>dog</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>457</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>cat</td>\n",
       "      <td>102</td>\n",
       "      <td>15</td>\n",
       "      <td>272</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>dog</td>\n",
       "      <td>84</td>\n",
       "      <td>31</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>dog</td>\n",
       "      <td>160</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>332</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "      <td>40</td>\n",
       "      <td>486</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height class  \\\n",
       "0  /Users/macbook/Downloads/archive-2/images/Cats...    500     333   dog   \n",
       "1  /Users/macbook/Downloads/archive-2/images/Cats...    375     500   cat   \n",
       "2  /Users/macbook/Downloads/archive-2/images/Cats...    300     225   dog   \n",
       "3  /Users/macbook/Downloads/archive-2/images/Cats...    375     500   dog   \n",
       "4  /Users/macbook/Downloads/archive-2/images/Cats...    500     332   cat   \n",
       "\n",
       "   xmin  ymin  xmax  ymax  \n",
       "0    10     5   457   305  \n",
       "1   102    15   272   204  \n",
       "2    84    31   216   171  \n",
       "3   160    59   256   179  \n",
       "4   250    40   486   242  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a93e415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    2498\n",
       "cat    1188\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = df['class'].value_counts()\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5c47cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0, 'cat': 1}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict = dict(zip(vc.keys().to_list(), np.arange(vc.shape[0])))\n",
    "classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f6d18b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog', 1: 'cat'}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num_to_name = dict(zip(np.arange(vc.shape[0]), vc.keys().to_list()))\n",
    "class_num_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e894d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].apply(lambda x: classes_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "208219b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bb9e1905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>new_path</th>\n",
       "      <th>new_bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>457</td>\n",
       "      <td>305</td>\n",
       "      <td>resized_images/Cats_Test2531.png</td>\n",
       "      <td>[6.0, 4.0, 274.0, 275.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>15</td>\n",
       "      <td>272</td>\n",
       "      <td>204</td>\n",
       "      <td>resized_images/Cats_Test1038.png</td>\n",
       "      <td>[81.0, 9.0, 218.0, 122.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>31</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "      <td>resized_images/Cats_Test134.png</td>\n",
       "      <td>[84.0, 41.0, 216.0, 229.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>179</td>\n",
       "      <td>resized_images/Cats_Test1986.png</td>\n",
       "      <td>[128.0, 35.0, 205.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>40</td>\n",
       "      <td>486</td>\n",
       "      <td>242</td>\n",
       "      <td>resized_images/Cats_Test652.png</td>\n",
       "      <td>[150.0, 36.0, 291.0, 219.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height  class  \\\n",
       "0  /Users/macbook/Downloads/archive-2/images/Cats...    500     333      0   \n",
       "1  /Users/macbook/Downloads/archive-2/images/Cats...    375     500      1   \n",
       "2  /Users/macbook/Downloads/archive-2/images/Cats...    300     225      0   \n",
       "3  /Users/macbook/Downloads/archive-2/images/Cats...    375     500      0   \n",
       "4  /Users/macbook/Downloads/archive-2/images/Cats...    500     332      1   \n",
       "\n",
       "   xmin  ymin  xmax  ymax                          new_path  \\\n",
       "0    10     5   457   305  resized_images/Cats_Test2531.png   \n",
       "1   102    15   272   204  resized_images/Cats_Test1038.png   \n",
       "2    84    31   216   171   resized_images/Cats_Test134.png   \n",
       "3   160    59   256   179  resized_images/Cats_Test1986.png   \n",
       "4   250    40   486   242   resized_images/Cats_Test652.png   \n",
       "\n",
       "                        new_bb  \n",
       "0     [6.0, 4.0, 274.0, 275.0]  \n",
       "1    [81.0, 9.0, 218.0, 122.0]  \n",
       "2   [84.0, 41.0, 216.0, 229.0]  \n",
       "3  [128.0, 35.0, 205.0, 107.0]  \n",
       "4  [150.0, 36.0, 291.0, 219.0]  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2a88827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_an_image_colo_to_rgb(image):\n",
    "    \n",
    "    change_color_from_to = cv2.COLOR_BGR2RGB\n",
    "    converted_colors_image = cv2.cvtColor(image, change_color_from_to)\n",
    "    \n",
    "    return converted_colors_image\n",
    "\n",
    "def read_image(image_path):\n",
    "    \n",
    "    image = cv2.imread(str(image_path))\n",
    "    \n",
    "    image = conver_an_image_colo_to_rgb(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def bb2mask(im, bb):\n",
    "    \n",
    "    \"\"\"Конвертируем bounding box в маску\"\"\"\n",
    "    \n",
    "    mask = np.zeros(im.shape[:-1])\n",
    "    bb = bb.astype(np.int)\n",
    "    x_min, y_min, x_max, y_max = bb\n",
    "    mask[y_min:y_max + 1, x_min:x_max + 1] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def mask2bb(mask):\n",
    "    \n",
    "    \"\"\"Конвертируем маску в bounding box, принимая 0 как фоновый ненулевой объект\"\"\"\n",
    "    \n",
    "    cols, rows = np.nonzero(mask)\n",
    "    \n",
    "    if len(cols) == 0: \n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    \n",
    "    x_min = np.min(rows)\n",
    "    y_min = np.min(cols)\n",
    "    x_max = np.max(rows)\n",
    "    y_max = np.max(cols)\n",
    "    \n",
    "    return np.array([x_min, y_min, x_max, y_max], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b2d6fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_an_image(image_path, write_path, bb, new_size):\n",
    "    \n",
    "    image = read_image(image_path)\n",
    "    mask = bb2mask(image, bb)\n",
    "    \n",
    "    resized_image = cv2.resize(image, (new_size, new_size))\n",
    "    resized_mask = cv2.resize(mask, (new_size, new_size))\n",
    "    \n",
    "    new_image_path = Path(str(write_path) + '/' + image_path.parts[-1])\n",
    "    \n",
    "    cv2.imwrite(str(new_image_path), conver_an_image_colo_to_rgb(resized_image))\n",
    "    \n",
    "    new_bb = mask2bb(resized_mask)\n",
    "    \n",
    "    return new_image_path, new_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8a8c6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(image_path, bb, cl, cl_dict):\n",
    "    \n",
    "    color = (np.array(color_palette('hls', 1)) * 255).astype(np.uint8)[0]\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(bb, outline=tuple(color), width=3)\n",
    "    \n",
    "    text = f\"{cl_dict[cl].upper()}\"\n",
    "    text_size = draw.textsize(text)\n",
    "    \n",
    "    text_x, text_y = text_size\n",
    "    \n",
    "    x_min, y_min = bb[:2]\n",
    "    \n",
    "    text_box_xy = [x_min, y_min + text_y, x_min + text_x, y_min]\n",
    "    text_xy = [x_min, y_min]\n",
    "    \n",
    "    draw.rectangle(text_box_xy, fill=tuple(color))\n",
    "    draw.text(text_xy, text, fill='white')\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5561de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_folder = Path('resized_images')\n",
    "\n",
    "image_path_column = 'filename'\n",
    "bb_columns = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "\n",
    "IMG_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "10382880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df_new_cols(x, write_path, new_size):\n",
    "\n",
    "    image_path = x[image_path_column]\n",
    "    bb = x[bb_columns].values\n",
    "    \n",
    "    new_path, new_bb = resize_an_image(image_path, write_path, bb, new_size)\n",
    "    \n",
    "    x['new_path'] = new_path\n",
    "    x['new_bb'] = new_bb\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d93d9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.mkdir(resized_images_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0c9e4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: add_to_df_new_cols(x, resized_images_folder, IMG_SIZE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f728390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>new_path</th>\n",
       "      <th>new_bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>dog</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>457</td>\n",
       "      <td>305</td>\n",
       "      <td>resized_images/Cats_Test2531.png</td>\n",
       "      <td>[6.0, 4.0, 274.0, 275.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>cat</td>\n",
       "      <td>102</td>\n",
       "      <td>15</td>\n",
       "      <td>272</td>\n",
       "      <td>204</td>\n",
       "      <td>resized_images/Cats_Test1038.png</td>\n",
       "      <td>[81.0, 9.0, 218.0, 122.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>dog</td>\n",
       "      <td>84</td>\n",
       "      <td>31</td>\n",
       "      <td>216</td>\n",
       "      <td>171</td>\n",
       "      <td>resized_images/Cats_Test134.png</td>\n",
       "      <td>[84.0, 41.0, 216.0, 229.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>dog</td>\n",
       "      <td>160</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>179</td>\n",
       "      <td>resized_images/Cats_Test1986.png</td>\n",
       "      <td>[128.0, 35.0, 205.0, 107.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Downloads/archive-2/images/Cats...</td>\n",
       "      <td>500</td>\n",
       "      <td>332</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "      <td>40</td>\n",
       "      <td>486</td>\n",
       "      <td>242</td>\n",
       "      <td>resized_images/Cats_Test652.png</td>\n",
       "      <td>[150.0, 36.0, 291.0, 219.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height class  \\\n",
       "0  /Users/macbook/Downloads/archive-2/images/Cats...    500     333   dog   \n",
       "1  /Users/macbook/Downloads/archive-2/images/Cats...    375     500   cat   \n",
       "2  /Users/macbook/Downloads/archive-2/images/Cats...    300     225   dog   \n",
       "3  /Users/macbook/Downloads/archive-2/images/Cats...    375     500   dog   \n",
       "4  /Users/macbook/Downloads/archive-2/images/Cats...    500     332   cat   \n",
       "\n",
       "   xmin  ymin  xmax  ymax                          new_path  \\\n",
       "0    10     5   457   305  resized_images/Cats_Test2531.png   \n",
       "1   102    15   272   204  resized_images/Cats_Test1038.png   \n",
       "2    84    31   216   171   resized_images/Cats_Test134.png   \n",
       "3   160    59   256   179  resized_images/Cats_Test1986.png   \n",
       "4   250    40   486   242   resized_images/Cats_Test652.png   \n",
       "\n",
       "                        new_bb  \n",
       "0     [6.0, 4.0, 274.0, 275.0]  \n",
       "1    [81.0, 9.0, 218.0, 122.0]  \n",
       "2   [84.0, 41.0, 216.0, 229.0]  \n",
       "3  [128.0, 35.0, 205.0, 107.0]  \n",
       "4  [150.0, 36.0, 291.0, 219.0]  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f12950df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e36aae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['new_path', 'new_bb']]\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "46d18cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalize(image):\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    \n",
    "    image -= imagenet_stats[0]\n",
    "    image /= imagenet_stats[1]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e519a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, paths, bbs, classes, transforms=None):\n",
    "        self.paths = paths.values\n",
    "        self.bbs = bbs.values\n",
    "        self.classes = classes.values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        path = self.paths[idx]\n",
    "        y_class = self.classes[idx]\n",
    "        box = self.bbs[idx]\n",
    "        box = torch.as_tensor([box], dtype=torch.float32)\n",
    "        \n",
    "        img = Image.open(path)\n",
    "        image_id = torch.tensor([idx])\n",
    "        labels = torch.as_tensor([y_class])\n",
    "        area = (box[:, 3] - box[:, 1]) * (box[:, 2] - box[:, 0])\n",
    "        iscrowd = torch.tensor([0])\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = box\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0170ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatsDogsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 2))\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3387d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train: bool):\n",
    "    transforms = []\n",
    "    \n",
    "    transforms.append(T.ToTensor())\n",
    "    \n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "adb8ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CatDogDataset(df['new_path'], df['new_bb'], df['class'], get_transform(train=True))\n",
    "dataset_valid = CatDogDataset(df['new_path'], df['new_bb'], df['class'], get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ac812898",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset_train)).tolist()\n",
    "\n",
    "dataset_train = Subset(dataset_train, indices[:-50])\n",
    "dataset_valid = Subset(dataset_valid, indices[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5a113aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b8a5d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(dataset_train, \n",
    "                      batch_size=2, \n",
    "                      shuffle=True, \n",
    "                      num_workers=4, \n",
    "                      collate_fn=collate_fn)\n",
    "\n",
    "dl_valid = DataLoader(dataset_valid, \n",
    "                      batch_size=1, \n",
    "                      shuffle=False, \n",
    "                      num_workers=4, \n",
    "                      collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8507d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = CatsDogsNet()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                         step_size=3, \n",
    "                                         gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "20b86a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-e682735a26c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Update the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pytorch_lessons/hw/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pytorch_lessons/hw/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    178\u001b[0m             ])\n\u001b[1;32m    179\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_one_epoch(model, optimizer, dl_train, device, epoch, print_freq=1)\n",
    "    \n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    evaluate(model, dl_valid, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffc1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
