{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "hw_5.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9043f2b5"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "id": "9043f2b5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33743448"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "33743448",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldybTilbE9fZ",
        "outputId": "6c62b464-d7a0-40b8-9cc0-78fce20ac8fb"
      },
      "source": [
        "!wget 'https://drive.google.com/uc?export=download&id=1nuMuI2dO0JXdU5MuZjGHADC1Y6jvanaw' -O new_skels.csv"
      ],
      "id": "ldybTilbE9fZ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 19:06:21--  https://drive.google.com/uc?export=download&id=1nuMuI2dO0JXdU5MuZjGHADC1Y6jvanaw\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.2.110, 2607:f8b0:4004:82f::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kb6elnck0cbdr66i4ri9g5gt357qmhl1/1625771175000/14273303898397132356/*/1nuMuI2dO0JXdU5MuZjGHADC1Y6jvanaw?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-08 19:06:23--  https://doc-00-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kb6elnck0cbdr66i4ri9g5gt357qmhl1/1625771175000/14273303898397132356/*/1nuMuI2dO0JXdU5MuZjGHADC1Y6jvanaw?e=download\n",
            "Resolving doc-00-58-docs.googleusercontent.com (doc-00-58-docs.googleusercontent.com)... 142.250.73.225, 2607:f8b0:4004:82a::2001\n",
            "Connecting to doc-00-58-docs.googleusercontent.com (doc-00-58-docs.googleusercontent.com)|142.250.73.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘new_skels.csv’\n",
            "\n",
            "new_skels.csv           [  <=>               ]  38.50M   139MB/s    in 0.3s    \n",
            "\n",
            "2021-07-08 19:06:23 (139 MB/s) - ‘new_skels.csv’ saved [40373406]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6660bdb4"
      },
      "source": [
        "1. Сгенерировать меньший датасет из 8-10 классов движения"
      ],
      "id": "6660bdb4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec2ce19e"
      },
      "source": [
        "skeletons_df = pd.read_csv('/content/new_skels.csv')"
      ],
      "id": "ec2ce19e",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "771408cc",
        "outputId": "ad905687-2ee3-4e39-c8b7-a275f853e4bb"
      },
      "source": [
        "skeletons_df.head()"
      ],
      "id": "771408cc",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>3336</th>\n",
              "      <th>3337</th>\n",
              "      <th>3338</th>\n",
              "      <th>3339</th>\n",
              "      <th>3340</th>\n",
              "      <th>3341</th>\n",
              "      <th>3342</th>\n",
              "      <th>3343</th>\n",
              "      <th>3344</th>\n",
              "      <th>3345</th>\n",
              "      <th>3346</th>\n",
              "      <th>3347</th>\n",
              "      <th>3348</th>\n",
              "      <th>3349</th>\n",
              "      <th>3350</th>\n",
              "      <th>3351</th>\n",
              "      <th>3352</th>\n",
              "      <th>3353</th>\n",
              "      <th>3354</th>\n",
              "      <th>3355</th>\n",
              "      <th>3356</th>\n",
              "      <th>3357</th>\n",
              "      <th>3358</th>\n",
              "      <th>3359</th>\n",
              "      <th>3360</th>\n",
              "      <th>3361</th>\n",
              "      <th>3362</th>\n",
              "      <th>3363</th>\n",
              "      <th>3364</th>\n",
              "      <th>3365</th>\n",
              "      <th>3366</th>\n",
              "      <th>3367</th>\n",
              "      <th>3368</th>\n",
              "      <th>3369</th>\n",
              "      <th>3370</th>\n",
              "      <th>3371</th>\n",
              "      <th>3372</th>\n",
              "      <th>3373</th>\n",
              "      <th>3374</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.107169</td>\n",
              "      <td>0.155336</td>\n",
              "      <td>3.774813</td>\n",
              "      <td>0.087842</td>\n",
              "      <td>0.424236</td>\n",
              "      <td>3.710918</td>\n",
              "      <td>0.068912</td>\n",
              "      <td>0.688434</td>\n",
              "      <td>3.634974</td>\n",
              "      <td>0.095212</td>\n",
              "      <td>0.807942</td>\n",
              "      <td>3.603217</td>\n",
              "      <td>-0.030894</td>\n",
              "      <td>0.570796</td>\n",
              "      <td>3.575153</td>\n",
              "      <td>-0.054834</td>\n",
              "      <td>0.338406</td>\n",
              "      <td>3.564177</td>\n",
              "      <td>-0.023961</td>\n",
              "      <td>0.113836</td>\n",
              "      <td>3.579079</td>\n",
              "      <td>-0.003036</td>\n",
              "      <td>0.071249</td>\n",
              "      <td>3.582160</td>\n",
              "      <td>0.202670</td>\n",
              "      <td>0.593185</td>\n",
              "      <td>3.712649</td>\n",
              "      <td>0.265672</td>\n",
              "      <td>0.382403</td>\n",
              "      <td>3.773768</td>\n",
              "      <td>0.335933</td>\n",
              "      <td>0.218966</td>\n",
              "      <td>3.774634</td>\n",
              "      <td>0.348793</td>\n",
              "      <td>0.138982</td>\n",
              "      <td>3.772001</td>\n",
              "      <td>0.051786</td>\n",
              "      <td>0.148485</td>\n",
              "      <td>3.711796</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018002</td>\n",
              "      <td>0.173563</td>\n",
              "      <td>3.738454</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>-0.120043</td>\n",
              "      <td>3.810589</td>\n",
              "      <td>-0.034193</td>\n",
              "      <td>-0.410203</td>\n",
              "      <td>3.955529</td>\n",
              "      <td>0.027257</td>\n",
              "      <td>-0.471157</td>\n",
              "      <td>3.989867</td>\n",
              "      <td>0.125138</td>\n",
              "      <td>0.180552</td>\n",
              "      <td>3.774267</td>\n",
              "      <td>0.123769</td>\n",
              "      <td>-0.101110</td>\n",
              "      <td>3.890709</td>\n",
              "      <td>0.077180</td>\n",
              "      <td>-0.422957</td>\n",
              "      <td>4.046787</td>\n",
              "      <td>0.114206</td>\n",
              "      <td>-0.478615</td>\n",
              "      <td>3.949024</td>\n",
              "      <td>0.059637</td>\n",
              "      <td>0.623877</td>\n",
              "      <td>3.668810</td>\n",
              "      <td>0.300735</td>\n",
              "      <td>0.539580</td>\n",
              "      <td>3.595297</td>\n",
              "      <td>0.275155</td>\n",
              "      <td>0.478890</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>0.204374</td>\n",
              "      <td>0.591374</td>\n",
              "      <td>3.486948</td>\n",
              "      <td>0.265206</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>3.454333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.073530</td>\n",
              "      <td>0.176115</td>\n",
              "      <td>3.790838</td>\n",
              "      <td>0.066357</td>\n",
              "      <td>0.431843</td>\n",
              "      <td>3.724868</td>\n",
              "      <td>0.057691</td>\n",
              "      <td>0.688121</td>\n",
              "      <td>3.649235</td>\n",
              "      <td>0.063602</td>\n",
              "      <td>0.803959</td>\n",
              "      <td>3.605012</td>\n",
              "      <td>-0.051390</td>\n",
              "      <td>0.576677</td>\n",
              "      <td>3.577165</td>\n",
              "      <td>0.060506</td>\n",
              "      <td>0.373254</td>\n",
              "      <td>3.536352</td>\n",
              "      <td>0.233468</td>\n",
              "      <td>0.523937</td>\n",
              "      <td>3.537280</td>\n",
              "      <td>0.312053</td>\n",
              "      <td>0.623063</td>\n",
              "      <td>3.524348</td>\n",
              "      <td>0.210907</td>\n",
              "      <td>0.603342</td>\n",
              "      <td>3.685688</td>\n",
              "      <td>0.375831</td>\n",
              "      <td>0.598065</td>\n",
              "      <td>3.628843</td>\n",
              "      <td>0.237076</td>\n",
              "      <td>0.584001</td>\n",
              "      <td>3.498875</td>\n",
              "      <td>0.213082</td>\n",
              "      <td>0.581713</td>\n",
              "      <td>3.494584</td>\n",
              "      <td>0.017938</td>\n",
              "      <td>0.173724</td>\n",
              "      <td>3.738734</td>\n",
              "      <td>0.003253</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039503</td>\n",
              "      <td>0.216764</td>\n",
              "      <td>3.724097</td>\n",
              "      <td>0.014837</td>\n",
              "      <td>-0.098823</td>\n",
              "      <td>3.804500</td>\n",
              "      <td>-0.001431</td>\n",
              "      <td>-0.460940</td>\n",
              "      <td>4.005896</td>\n",
              "      <td>0.033438</td>\n",
              "      <td>-0.532394</td>\n",
              "      <td>3.925732</td>\n",
              "      <td>0.147237</td>\n",
              "      <td>0.245336</td>\n",
              "      <td>3.764869</td>\n",
              "      <td>0.151130</td>\n",
              "      <td>-0.048351</td>\n",
              "      <td>3.856603</td>\n",
              "      <td>0.076178</td>\n",
              "      <td>-0.385269</td>\n",
              "      <td>4.068417</td>\n",
              "      <td>0.066847</td>\n",
              "      <td>-0.486819</td>\n",
              "      <td>4.028674</td>\n",
              "      <td>0.051623</td>\n",
              "      <td>0.600825</td>\n",
              "      <td>3.401490</td>\n",
              "      <td>0.051330</td>\n",
              "      <td>0.775686</td>\n",
              "      <td>3.147952</td>\n",
              "      <td>0.042513</td>\n",
              "      <td>0.782981</td>\n",
              "      <td>3.131667</td>\n",
              "      <td>0.184349</td>\n",
              "      <td>0.609286</td>\n",
              "      <td>3.721297</td>\n",
              "      <td>0.140844</td>\n",
              "      <td>0.632283</td>\n",
              "      <td>3.666000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.101858</td>\n",
              "      <td>0.157313</td>\n",
              "      <td>3.801223</td>\n",
              "      <td>0.106297</td>\n",
              "      <td>0.410928</td>\n",
              "      <td>3.751010</td>\n",
              "      <td>0.110345</td>\n",
              "      <td>0.659381</td>\n",
              "      <td>3.690153</td>\n",
              "      <td>0.069111</td>\n",
              "      <td>0.729826</td>\n",
              "      <td>3.626038</td>\n",
              "      <td>0.007819</td>\n",
              "      <td>0.556308</td>\n",
              "      <td>3.768062</td>\n",
              "      <td>-0.011128</td>\n",
              "      <td>0.582839</td>\n",
              "      <td>3.525778</td>\n",
              "      <td>0.056220</td>\n",
              "      <td>0.643828</td>\n",
              "      <td>3.305092</td>\n",
              "      <td>0.035716</td>\n",
              "      <td>0.686819</td>\n",
              "      <td>3.120791</td>\n",
              "      <td>0.170006</td>\n",
              "      <td>0.596938</td>\n",
              "      <td>3.717140</td>\n",
              "      <td>0.251414</td>\n",
              "      <td>0.652381</td>\n",
              "      <td>3.494979</td>\n",
              "      <td>0.234761</td>\n",
              "      <td>0.585732</td>\n",
              "      <td>3.640310</td>\n",
              "      <td>0.224816</td>\n",
              "      <td>0.651398</td>\n",
              "      <td>3.693118</td>\n",
              "      <td>0.039176</td>\n",
              "      <td>0.153576</td>\n",
              "      <td>3.758578</td>\n",
              "      <td>0.014972</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068534</td>\n",
              "      <td>0.136442</td>\n",
              "      <td>3.691469</td>\n",
              "      <td>-0.016502</td>\n",
              "      <td>-0.140213</td>\n",
              "      <td>3.826027</td>\n",
              "      <td>-0.020635</td>\n",
              "      <td>-0.406493</td>\n",
              "      <td>3.960613</td>\n",
              "      <td>0.033393</td>\n",
              "      <td>-0.480396</td>\n",
              "      <td>3.986403</td>\n",
              "      <td>0.169888</td>\n",
              "      <td>0.137194</td>\n",
              "      <td>3.737295</td>\n",
              "      <td>0.174022</td>\n",
              "      <td>-0.121408</td>\n",
              "      <td>3.647927</td>\n",
              "      <td>0.104815</td>\n",
              "      <td>-0.356079</td>\n",
              "      <td>3.965588</td>\n",
              "      <td>0.149731</td>\n",
              "      <td>-0.409237</td>\n",
              "      <td>3.870815</td>\n",
              "      <td>0.094339</td>\n",
              "      <td>0.623390</td>\n",
              "      <td>3.684305</td>\n",
              "      <td>0.123914</td>\n",
              "      <td>0.249691</td>\n",
              "      <td>3.581933</td>\n",
              "      <td>0.023094</td>\n",
              "      <td>0.287091</td>\n",
              "      <td>3.642000</td>\n",
              "      <td>0.188379</td>\n",
              "      <td>0.091022</td>\n",
              "      <td>3.504948</td>\n",
              "      <td>0.142348</td>\n",
              "      <td>0.125880</td>\n",
              "      <td>3.552154</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.017126</td>\n",
              "      <td>-0.549648</td>\n",
              "      <td>2.910658</td>\n",
              "      <td>0.008213</td>\n",
              "      <td>-0.278351</td>\n",
              "      <td>2.923760</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>-0.010747</td>\n",
              "      <td>2.911902</td>\n",
              "      <td>0.035279</td>\n",
              "      <td>0.112427</td>\n",
              "      <td>2.903560</td>\n",
              "      <td>-0.106856</td>\n",
              "      <td>-0.106927</td>\n",
              "      <td>2.904222</td>\n",
              "      <td>-0.111414</td>\n",
              "      <td>-0.303022</td>\n",
              "      <td>2.865315</td>\n",
              "      <td>-0.030457</td>\n",
              "      <td>-0.430152</td>\n",
              "      <td>2.728033</td>\n",
              "      <td>-0.010259</td>\n",
              "      <td>-0.458600</td>\n",
              "      <td>2.678936</td>\n",
              "      <td>0.175180</td>\n",
              "      <td>-0.111796</td>\n",
              "      <td>2.903249</td>\n",
              "      <td>0.204783</td>\n",
              "      <td>-0.307510</td>\n",
              "      <td>2.886162</td>\n",
              "      <td>0.106341</td>\n",
              "      <td>-0.434892</td>\n",
              "      <td>2.747414</td>\n",
              "      <td>0.084417</td>\n",
              "      <td>-0.467307</td>\n",
              "      <td>2.701238</td>\n",
              "      <td>-0.082788</td>\n",
              "      <td>-0.537297</td>\n",
              "      <td>2.882745</td>\n",
              "      <td>-0.013058</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.068641</td>\n",
              "      <td>-0.571650</td>\n",
              "      <td>2.915643</td>\n",
              "      <td>-0.078144</td>\n",
              "      <td>-0.494346</td>\n",
              "      <td>2.586306</td>\n",
              "      <td>-0.046216</td>\n",
              "      <td>-0.848132</td>\n",
              "      <td>2.589291</td>\n",
              "      <td>-0.048863</td>\n",
              "      <td>-0.900273</td>\n",
              "      <td>2.528113</td>\n",
              "      <td>0.046701</td>\n",
              "      <td>-0.560144</td>\n",
              "      <td>2.889013</td>\n",
              "      <td>0.116660</td>\n",
              "      <td>-0.373217</td>\n",
              "      <td>2.635323</td>\n",
              "      <td>-0.005860</td>\n",
              "      <td>-0.697047</td>\n",
              "      <td>2.511928</td>\n",
              "      <td>-0.028205</td>\n",
              "      <td>-0.775199</td>\n",
              "      <td>2.503626</td>\n",
              "      <td>-0.028977</td>\n",
              "      <td>-0.110459</td>\n",
              "      <td>2.851648</td>\n",
              "      <td>-0.283529</td>\n",
              "      <td>-0.468955</td>\n",
              "      <td>2.834120</td>\n",
              "      <td>-0.266852</td>\n",
              "      <td>-0.429082</td>\n",
              "      <td>2.857666</td>\n",
              "      <td>-0.044864</td>\n",
              "      <td>-0.524298</td>\n",
              "      <td>2.542837</td>\n",
              "      <td>-0.037103</td>\n",
              "      <td>-0.439468</td>\n",
              "      <td>2.542185</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.012737</td>\n",
              "      <td>-0.566869</td>\n",
              "      <td>2.961922</td>\n",
              "      <td>-0.019491</td>\n",
              "      <td>-0.305559</td>\n",
              "      <td>2.894948</td>\n",
              "      <td>-0.032567</td>\n",
              "      <td>-0.047151</td>\n",
              "      <td>2.827832</td>\n",
              "      <td>-0.062442</td>\n",
              "      <td>0.069258</td>\n",
              "      <td>2.819594</td>\n",
              "      <td>-0.147424</td>\n",
              "      <td>-0.150081</td>\n",
              "      <td>2.844229</td>\n",
              "      <td>-0.194911</td>\n",
              "      <td>-0.226845</td>\n",
              "      <td>3.038487</td>\n",
              "      <td>-0.295766</td>\n",
              "      <td>-0.356791</td>\n",
              "      <td>2.983296</td>\n",
              "      <td>-0.295845</td>\n",
              "      <td>-0.407596</td>\n",
              "      <td>2.866120</td>\n",
              "      <td>0.106113</td>\n",
              "      <td>-0.101370</td>\n",
              "      <td>2.802265</td>\n",
              "      <td>0.095277</td>\n",
              "      <td>-0.301241</td>\n",
              "      <td>2.668104</td>\n",
              "      <td>0.027370</td>\n",
              "      <td>-0.437057</td>\n",
              "      <td>2.579191</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>-0.478563</td>\n",
              "      <td>2.566986</td>\n",
              "      <td>-0.071199</td>\n",
              "      <td>-0.566213</td>\n",
              "      <td>2.942274</td>\n",
              "      <td>-0.085087</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044147</td>\n",
              "      <td>-0.508898</td>\n",
              "      <td>2.924855</td>\n",
              "      <td>-0.047596</td>\n",
              "      <td>-0.591335</td>\n",
              "      <td>2.588038</td>\n",
              "      <td>-0.051339</td>\n",
              "      <td>-0.854784</td>\n",
              "      <td>2.592133</td>\n",
              "      <td>-0.046010</td>\n",
              "      <td>-0.915295</td>\n",
              "      <td>2.515439</td>\n",
              "      <td>0.080394</td>\n",
              "      <td>-0.491245</td>\n",
              "      <td>2.918082</td>\n",
              "      <td>0.105395</td>\n",
              "      <td>-0.594797</td>\n",
              "      <td>2.588854</td>\n",
              "      <td>0.099358</td>\n",
              "      <td>-0.858555</td>\n",
              "      <td>2.572868</td>\n",
              "      <td>0.089104</td>\n",
              "      <td>-0.910380</td>\n",
              "      <td>2.466472</td>\n",
              "      <td>-0.018910</td>\n",
              "      <td>-0.110001</td>\n",
              "      <td>2.794079</td>\n",
              "      <td>-0.041126</td>\n",
              "      <td>-0.473166</td>\n",
              "      <td>2.507934</td>\n",
              "      <td>-0.067171</td>\n",
              "      <td>-0.438300</td>\n",
              "      <td>2.529875</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>-0.445410</td>\n",
              "      <td>2.366435</td>\n",
              "      <td>0.067471</td>\n",
              "      <td>-0.449583</td>\n",
              "      <td>2.386429</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3376 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...      3372      3373      3374  labels\n",
              "0  0.107169  0.155336  3.774813  0.087842  ...  0.265206  0.617021  3.454333       1\n",
              "1  0.073530  0.176115  3.790838  0.066357  ...  0.140844  0.632283  3.666000       1\n",
              "2  0.101858  0.157313  3.801223  0.106297  ...  0.142348  0.125880  3.552154       1\n",
              "3 -0.017126 -0.549648  2.910658  0.008213  ... -0.037103 -0.439468  2.542185       2\n",
              "4 -0.012737 -0.566869  2.961922 -0.019491  ...  0.067471 -0.449583  2.386429       2\n",
              "\n",
              "[5 rows x 3376 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da9e177a",
        "outputId": "1685006e-a365-463b-c1ff-40cc5624eb1e"
      },
      "source": [
        "skeletons_df.info()"
      ],
      "id": "da9e177a",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1202 entries, 0 to 1201\n",
            "Columns: 3376 entries, 0 to labels\n",
            "dtypes: float64(3375), int64(1)\n",
            "memory usage: 31.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "676822c4",
        "outputId": "1a662939-5cb2-4dae-a1d9-ba09eafcbd77"
      },
      "source": [
        "skeletons_df.shape"
      ],
      "id": "676822c4",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1202, 3376)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c433392",
        "outputId": "33fb1a8c-4da1-4f85-f775-03c46f2f6ccc"
      },
      "source": [
        "skeletons_df.labels.value_counts()"
      ],
      "id": "3c433392",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    123\n",
              "6    121\n",
              "9    120\n",
              "8    120\n",
              "7    120\n",
              "5    120\n",
              "4    120\n",
              "3    120\n",
              "1    120\n",
              "0    118\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c6ecd35",
        "outputId": "51d6f3b9-2ec3-4adb-d5aa-3335e278c831"
      },
      "source": [
        "action_classes =  {7: 0, 15: 1, 17: 2, 3: 3, 5: 4, 9: 5, 19: 6, 13: 7, 1: 8, 11: 9}\n",
        "    \n",
        "LABELS = {\n",
        "    1: 'drink water',\n",
        "    3: 'brushing teeth',\n",
        "    5: 'drop',\n",
        "    7: 'throw',\n",
        "    9: 'standing up (from sitting position)',\n",
        "    11: 'reading',\n",
        "    13: 'tear up paper',\n",
        "    15: 'take off jacket',\n",
        "    17: 'take off a shoe',\n",
        "    19: 'take off glasses',\n",
        "}\n",
        "\n",
        "LABELS = {action_classes[k]:v for k,v in LABELS.items()}\n",
        "LABELS"
      ],
      "id": "8c6ecd35",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'throw',\n",
              " 1: 'take off jacket',\n",
              " 2: 'take off a shoe',\n",
              " 3: 'brushing teeth',\n",
              " 4: 'drop',\n",
              " 5: 'standing up (from sitting position)',\n",
              " 6: 'take off glasses',\n",
              " 7: 'tear up paper',\n",
              " 8: 'drink water',\n",
              " 9: 'reading'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8e9aa5"
      },
      "source": [
        "2. Обучить уже существующую модель (предварительно проанализировав, какие параметры модели нужно изменить)"
      ],
      "id": "9e8e9aa5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6b3e70d"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, layer_num):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, \n",
        "                            hidden_dim, \n",
        "                            layer_num, \n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.dr = nn.Dropout2d(0.1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        lstm_out, (hn, cn) = self.lstm(x)\n",
        "        \n",
        "        out = self.fc(lstm_out[:, -1])\n",
        "        \n",
        "        return out"
      ],
      "id": "b6b3e70d",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d33d7eed"
      },
      "source": [
        "frames = 45"
      ],
      "id": "d33d7eed",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6cc1281"
      },
      "source": [
        "class SkeletonDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.labels = data.iloc[:, -1]\n",
        "        self.data_len = len(self.data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.data_len\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = np.asarray(self.data.iloc[idx, :-1]).reshape(frames, 25 * 3)\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            item = self.transform(item)\n",
        "        \n",
        "        return item, label"
      ],
      "id": "b6cc1281",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1e55715"
      },
      "source": [
        "dataset = SkeletonDataset(skeletons_df)"
      ],
      "id": "d1e55715",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fab2cc1"
      },
      "source": [
        "train_len = int(0.75*len(dataset))\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset,\n",
        "    [train_len, len(dataset) - train_len]\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16, \n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=1, \n",
        "    shuffle=False\n",
        ")"
      ],
      "id": "0fab2cc1",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5de2ed",
        "outputId": "35757dd4-bf89-42fe-a7c3-0898456a0a01"
      },
      "source": [
        "n_hidden = 128\n",
        "n_joints = 25 * 3\n",
        "n_categories = len(LABELS)\n",
        "n_layer = 2\n",
        "rnn = LSTM_net(\n",
        "    n_joints,\n",
        "    n_hidden,\n",
        "    n_categories,\n",
        "    n_layer\n",
        ")\n",
        "rnn.to(device)"
      ],
      "id": "bd5de2ed",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_net(\n",
              "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
              "  (dr): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bd7394e"
      },
      "source": [
        "def class_from_output(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    class_i = top_i[0].item()\n",
        "    return LABELS[class_i], class_i\n",
        "\n",
        "\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {int(s)}s'"
      ],
      "id": "0bd7394e",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c3e3cb5"
      },
      "source": [
        "def train(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  learning_rate = 0.0007\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  all_losses = []\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "\n",
        "\n",
        "  for epoch in range(150):  \n",
        "      current_loss = 0\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          \n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          optimizer.zero_grad()\n",
        "      \n",
        "          output = model(inputs.float())\n",
        "          loss = criterion(output, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step() \n",
        "\n",
        "          current_loss += loss.item()\n",
        "          pred_label = LABELS[int(labels[0])]\n",
        "\n",
        "          if counter % 500 == 0:\n",
        "              guess, guess_i = class_from_output(output)\n",
        "              correct = '✓' if guess == pred_label else f'✗ ({pred_label})'\n",
        "              print(f'epoch : {epoch} iter : {i} ({time_since(start)})', end=' ')\n",
        "              print(f'{loss:.4f}  / {guess} {correct}')\n",
        "\n",
        "          \n",
        "          counter = counter + 1\n",
        "          \n",
        "      if counter % 100 == 0:\n",
        "          all_losses.append(current_loss / 25)\n",
        "          current_loss = 0"
      ],
      "id": "4c3e3cb5",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aj23TkBeTn0",
        "outputId": "b717c14f-d236-407f-a9bc-b1eb1c427bef"
      },
      "source": [
        "n_hidden = 128\n",
        "n_joints = 25 * 3\n",
        "n_categories = len(LABELS)\n",
        "n_layer = 2\n",
        "\n",
        "rnn = LSTM_net(\n",
        "    n_joints,\n",
        "    n_hidden,\n",
        "    n_categories,\n",
        "    n_layer\n",
        ")\n",
        "rnn.to(device)\n",
        "\n",
        "train(rnn)"
      ],
      "id": "-Aj23TkBeTn0",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 iter : 0 (0m 0s) 2.3266  / drop ✗ (take off glasses)\n",
            "epoch : 8 iter : 44 (0m 16s) 2.2839  / drop ✗ (throw)\n",
            "epoch : 17 iter : 31 (0m 32s) 2.2746  / drink water ✗ (throw)\n",
            "epoch : 26 iter : 18 (0m 48s) 2.1940  / take off a shoe ✓\n",
            "epoch : 35 iter : 5 (1m 4s) 2.2370  / drink water ✗ (take off a shoe)\n",
            "epoch : 43 iter : 49 (1m 21s) 2.2343  / take off a shoe ✓\n",
            "epoch : 52 iter : 36 (1m 37s) 2.1431  / drink water ✗ (reading)\n",
            "epoch : 61 iter : 23 (1m 53s) 1.9214  / take off a shoe ✓\n",
            "epoch : 70 iter : 10 (2m 9s) 2.2974  / drop ✗ (reading)\n",
            "epoch : 78 iter : 54 (2m 26s) 2.0500  / take off a shoe ✗ (drop)\n",
            "epoch : 87 iter : 41 (2m 42s) 2.0010  / standing up (from sitting position) ✓\n",
            "epoch : 96 iter : 28 (2m 58s) 1.8940  / drink water ✓\n",
            "epoch : 105 iter : 15 (3m 14s) 1.6701  / drink water ✗ (throw)\n",
            "epoch : 114 iter : 2 (3m 31s) 1.8835  / drop ✓\n",
            "epoch : 122 iter : 46 (3m 47s) 1.7551  / standing up (from sitting position) ✗ (throw)\n",
            "epoch : 131 iter : 33 (4m 3s) 1.7493  / reading ✗ (drink water)\n",
            "epoch : 140 iter : 20 (4m 19s) 1.4190  / drop ✗ (take off jacket)\n",
            "epoch : 149 iter : 7 (4m 36s) 1.6286  / tear up paper ✗ (take off glasses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f98f81"
      },
      "source": [
        "3. Изменить модель: посмотреть зависимость от количества LSTM модулей в модели"
      ],
      "id": "e2f98f81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07fae6f8"
      },
      "source": [
        "class LSTM_net_2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, layer_num):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, \n",
        "                            hidden_dim, \n",
        "                            layer_num, \n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.lstm_1 = nn.LSTM(hidden_dim, \n",
        "                          hidden_dim, \n",
        "                          layer_num, \n",
        "                          batch_first=True)\n",
        "        \n",
        "        self.dr = nn.Dropout2d(0.1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, (hn, cn) = self.lstm(x)\n",
        "\n",
        "        x, (hn, cn) = self.lstm_1(x, (hn, cn))\n",
        "        \n",
        "        out = self.fc(x[:, -1])\n",
        "        \n",
        "        return out"
      ],
      "id": "07fae6f8",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a2cc46b",
        "outputId": "40cf671f-fd05-44bd-eeb6-2ac93159657c"
      },
      "source": [
        "n_hidden = 128\n",
        "n_joints = 25 * 3\n",
        "n_categories = len(LABELS)\n",
        "n_layer = 2\n",
        "\n",
        "rnn = LSTM_net_2(\n",
        "    n_joints,\n",
        "    n_hidden,\n",
        "    n_categories,\n",
        "    n_layer\n",
        ")\n",
        "rnn.to(device)\n",
        "\n",
        "train(rnn)"
      ],
      "id": "4a2cc46b",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 iter : 0 (0m 0s) 2.2736  / standing up (from sitting position) ✗ (drop)\n",
            "epoch : 8 iter : 44 (0m 18s) 2.2990  / drop ✗ (standing up (from sitting position))\n",
            "epoch : 17 iter : 31 (0m 36s) 2.3086  / drop ✗ (brushing teeth)\n",
            "epoch : 26 iter : 18 (0m 54s) 2.2974  / drop ✗ (take off jacket)\n",
            "epoch : 35 iter : 5 (1m 12s) 2.2992  / drop ✗ (standing up (from sitting position))\n",
            "epoch : 43 iter : 49 (1m 30s) 2.2992  / drop ✓\n",
            "epoch : 52 iter : 36 (1m 49s) 2.2807  / drop ✓\n",
            "epoch : 61 iter : 23 (2m 7s) 2.3097  / drop ✗ (take off a shoe)\n",
            "epoch : 70 iter : 10 (2m 25s) 2.2862  / drop ✗ (drink water)\n",
            "epoch : 78 iter : 54 (2m 43s) 2.3084  / drop ✗ (take off a shoe)\n",
            "epoch : 87 iter : 41 (3m 1s) 2.2813  / drop ✓\n",
            "epoch : 96 iter : 28 (3m 20s) 2.2862  / drop ✗ (standing up (from sitting position))\n",
            "epoch : 105 iter : 15 (3m 38s) 2.3014  / drop ✗ (tear up paper)\n",
            "epoch : 114 iter : 2 (3m 56s) 2.2953  / drop ✗ (take off glasses)\n",
            "epoch : 122 iter : 46 (4m 14s) 2.3046  / drop ✗ (take off glasses)\n",
            "epoch : 131 iter : 33 (4m 32s) 2.3021  / drop ✗ (take off glasses)\n",
            "epoch : 140 iter : 20 (4m 51s) 2.2831  / drop ✗ (take off glasses)\n",
            "epoch : 149 iter : 7 (5m 9s) 2.2518  / drink water ✓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0JKWYSkLSM"
      },
      "source": [
        "class LSTM_net_3(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, layer_num):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, \n",
        "                            hidden_dim, \n",
        "                            layer_num, \n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.lstm_1 = nn.LSTM(hidden_dim, \n",
        "                              hidden_dim, \n",
        "                              layer_num, \n",
        "                              batch_first=True)\n",
        "        \n",
        "        self.lstm_2 = nn.LSTM(hidden_dim, \n",
        "                              hidden_dim, \n",
        "                              layer_num, \n",
        "                              batch_first=True)\n",
        "        \n",
        "        self.dr = nn.Dropout2d(0.1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, (hn, cn) = self.lstm(x)\n",
        "\n",
        "        x, (hn, cn) = self.lstm_1(x, (hn, cn))\n",
        "\n",
        "        x, (hn, cn) = self.lstm_2(x, (hn, cn))\n",
        "\n",
        "        out = self.fc(x[:, -1])\n",
        "        \n",
        "        return out"
      ],
      "id": "QY0JKWYSkLSM",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdNQdERYkc1P",
        "outputId": "ca2e37b8-c484-44fe-bc11-68d223c671e5"
      },
      "source": [
        "n_hidden = 128\n",
        "n_joints = 25 * 3\n",
        "n_categories = len(LABELS)\n",
        "n_layer = 2\n",
        "\n",
        "rnn = LSTM_net_3(\n",
        "    n_joints,\n",
        "    n_hidden,\n",
        "    n_categories,\n",
        "    n_layer\n",
        ")\n",
        "rnn.to(device)\n",
        "\n",
        "train(rnn)"
      ],
      "id": "YdNQdERYkc1P",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 iter : 0 (0m 0s) 2.3028  / drink water ✓\n",
            "epoch : 8 iter : 44 (0m 20s) 2.3054  / drink water ✗ (standing up (from sitting position))\n",
            "epoch : 17 iter : 31 (0m 40s) 2.3082  / drink water ✗ (brushing teeth)\n",
            "epoch : 26 iter : 18 (1m 1s) 2.2995  / drink water ✗ (brushing teeth)\n",
            "epoch : 35 iter : 5 (1m 21s) 2.2987  / drop ✗ (brushing teeth)\n",
            "epoch : 43 iter : 49 (1m 41s) 2.3019  / drop ✗ (drink water)\n",
            "epoch : 52 iter : 36 (2m 2s) 2.3060  / drop ✗ (brushing teeth)\n",
            "epoch : 61 iter : 23 (2m 22s) 2.2970  / drop ✗ (drink water)\n",
            "epoch : 70 iter : 10 (2m 42s) 2.3071  / drop ✗ (reading)\n",
            "epoch : 78 iter : 54 (3m 2s) 2.2855  / drop ✗ (standing up (from sitting position))\n",
            "epoch : 87 iter : 41 (3m 23s) 2.2860  / drop ✗ (brushing teeth)\n",
            "epoch : 96 iter : 28 (3m 43s) 2.2971  / drop ✗ (tear up paper)\n",
            "epoch : 105 iter : 15 (4m 4s) 2.3065  / drop ✗ (drink water)\n",
            "epoch : 114 iter : 2 (4m 24s) 2.3051  / drop ✗ (take off glasses)\n",
            "epoch : 122 iter : 46 (4m 44s) 2.2941  / drop ✗ (tear up paper)\n",
            "epoch : 131 iter : 33 (5m 5s) 2.3068  / drop ✗ (tear up paper)\n",
            "epoch : 140 iter : 20 (5m 25s) 2.3093  / drop ✓\n",
            "epoch : 149 iter : 7 (5m 45s) 2.2865  / drop ✗ (take off jacket)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bafb4a9"
      },
      "source": [
        "4. *Сгенерировать другой датасет с меньшим количеством “кадров” в серии и сравнить улучшилось или ухудшилось качество предсказания. Провести несколько таких итераций, дать свою оценку уменьшению и увеличению кадров, назвать оптимальное, на ваш взгляд, их количество."
      ],
      "id": "0bafb4a9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e0afe43"
      },
      "source": [
        ""
      ],
      "id": "9e0afe43",
      "execution_count": null,
      "outputs": []
    }
  ]
}